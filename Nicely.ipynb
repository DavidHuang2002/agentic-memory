{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7d5cc0-35d8-4f94-a68e-d0876417de7b",
   "metadata": {},
   "source": [
    "**Instantiate the Language Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3145ac1f-81bf-4aa0-a542-1ebc24c2ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "                temperature=0.7, \n",
    "                 model=\"gpt-4o\",\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cb3d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompts\n",
    "\n",
    "# system prompt\n",
    "\n",
    "# episodic memory reflection prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071d2399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant variables\n",
    "\n",
    "collection_name = \"nicely_episodic_memory\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ca92a-70c4-4d94-afcd-4910d8a83bb2",
   "metadata": {},
   "source": [
    "**Create Simple Back & Forth Chat Flow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f3d3fa7-2109-449b-95f6-077b10622704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Message:  I'm sorry, I don't have access to your personal information, so I don't know your name.\n",
      "\n",
      "AI Message:  Nice to meet you, David! How can I assist you today?\n",
      "\n",
      "AI Message:  Your name is David.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Define System Prompt\n",
    "system_prompt = SystemMessage(\"You are a helpful AI Assistant. Answer the User's queries succinctly in one sentence.\")\n",
    "\n",
    "# Start Storage for Historical Message History\n",
    "messages = [system_prompt]\n",
    "\n",
    "while True:\n",
    "\n",
    "    # Get User's Message\n",
    "    user_message = HumanMessage(input(\"\\nUser: \"))\n",
    "    \n",
    "    if user_message.content.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        # Extend Messages List With User Message\n",
    "        messages.append(user_message)\n",
    "\n",
    "    # Pass Entire Message Sequence to LLM to Generate Response\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    print(\"\\nAI Message: \", response.content)\n",
    "\n",
    "    # Add AI's Response to Message List\n",
    "    messages.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f0bb18-730e-4bf7-bc91-d60f60c28d32",
   "metadata": {},
   "source": [
    "Keeping track of our total conversation allows the LLM to use prior messages and interactions as context for immediate responses during an ongoing conversation, keeping our current interaction in working memory and recalling working memory through attaching it as context for subsequent response generations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61dddc2a-9ad6-49e5-8e1a-1cfad3f358da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Message 1 - SYSTEM:  You are a helpful AI Assistant. Answer the User's queries succinctly in one sentence.\n",
      "\n",
      "Message 2 - HUMAN:  whats my name\n",
      "\n",
      "Message 3 - AI:  I'm sorry, I don't have access to your personal information, so I don't know your name.\n",
      "\n",
      "Message 4 - HUMAN:  my name is david\n",
      "\n",
      "Message 5 - AI:  Nice to meet you, David! How can I assist you today?\n",
      "\n",
      "Message 6 - HUMAN:  what is my name\n",
      "\n",
      "Message 7 - AI:  Your name is David.\n"
     ]
    }
   ],
   "source": [
    "# Looking into our Memory\n",
    "\n",
    "for i in range(len(messages)):\n",
    "    print(f\"\\nMessage {i+1} - {messages[i].type.upper()}: \", messages[i].content)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c234c48f-54d9-4bc7-b620-88c7c38d1a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "reflection_prompt_template = \"\"\"\n",
    "You are analyzing conversations about research papers to create memories that will help guide future interactions. Your task is to extract key elements that would be most helpful when encountering similar academic discussions in the future.\n",
    "\n",
    "Review the conversation and create a memory reflection following these rules:\n",
    "\n",
    "1. For any field where you don't have enough information or the field isn't relevant, use \"N/A\"\n",
    "2. Be extremely concise - each string should be one clear, actionable sentence\n",
    "3. Focus only on information that would be useful for handling similar future conversations\n",
    "4. Context_tags should be specific enough to match similar situations but general enough to be reusable\n",
    "\n",
    "Output valid JSON in exactly this format:\n",
    "{{\n",
    "    \"context_tags\": [              // 2-4 keywords that would help identify similar future conversations\n",
    "        string,                    // Use field-specific terms like \"deep_learning\", \"methodology_question\", \"results_interpretation\"\n",
    "        ...\n",
    "    ],\n",
    "    \"conversation_summary\": string, // One sentence describing what the conversation accomplished\n",
    "    \"what_worked\": string,         // Most effective approach or strategy used in this conversation\n",
    "    \"what_to_avoid\": string        // Most important pitfall or ineffective approach to avoid\n",
    "}}\n",
    "\n",
    "Examples:\n",
    "- Good context_tags: [\"transformer_architecture\", \"attention_mechanism\", \"methodology_comparison\"]\n",
    "- Bad context_tags: [\"machine_learning\", \"paper_discussion\", \"questions\"]\n",
    "\n",
    "- Good conversation_summary: \"Explained how the attention mechanism in the BERT paper differs from traditional transformer architectures\"\n",
    "- Bad conversation_summary: \"Discussed a machine learning paper\"\n",
    "\n",
    "- Good what_worked: \"Using analogies from matrix multiplication to explain attention score calculations\"\n",
    "- Bad what_worked: \"Explained the technical concepts well\"\n",
    "\n",
    "- Good what_to_avoid: \"Diving into mathematical formulas before establishing user's familiarity with linear algebra fundamentals\"\n",
    "- Bad what_to_avoid: \"Used complicated language\"\n",
    "\n",
    "Additional examples for different research scenarios:\n",
    "\n",
    "Context tags examples:\n",
    "- [\"experimental_design\", \"control_groups\", \"methodology_critique\"]\n",
    "- [\"statistical_significance\", \"p_value_interpretation\", \"sample_size\"]\n",
    "- [\"research_limitations\", \"future_work\", \"methodology_gaps\"]\n",
    "\n",
    "Conversation summary examples:\n",
    "- \"Clarified why the paper's cross-validation approach was more robust than traditional hold-out methods\"\n",
    "- \"Helped identify potential confounding variables in the study's experimental design\"\n",
    "\n",
    "What worked examples:\n",
    "- \"Breaking down complex statistical concepts using visual analogies and real-world examples\"\n",
    "- \"Connecting the paper's methodology to similar approaches in related seminal papers\"\n",
    "\n",
    "What to avoid examples:\n",
    "- \"Assuming familiarity with domain-specific jargon without first checking understanding\"\n",
    "- \"Over-focusing on mathematical proofs when the user needed intuitive understanding\"\n",
    "\n",
    "Do not include any text outside the JSON object in your response.\n",
    "\n",
    "Here is the prior conversation:\n",
    "\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "reflection_prompt = ChatPromptTemplate.from_template(reflection_prompt_template)\n",
    "\n",
    "reflect = reflection_prompt | llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d823b6-2752-4bb1-9e54-9fcb29fc78c7",
   "metadata": {},
   "source": [
    "**Format Conversation Helper Function**\n",
    "\n",
    "Cleans up the conversation by removing the system prompt, effectively only returning a string of the relevant conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "380b3302-cd69-4e4a-9b44-eaf3209394bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUMAN: whats my name\n",
      "AI: I'm sorry, I don't have access to your personal information, so I don't know your name.\n",
      "HUMAN: my name is david\n",
      "AI: Nice to meet you, David! How can I assist you today?\n",
      "HUMAN: what is my name\n",
      "AI: Your name is David.\n"
     ]
    }
   ],
   "source": [
    "def format_conversation(messages):\n",
    "    \n",
    "    # Create an empty list placeholder\n",
    "    conversation = []\n",
    "    \n",
    "    # Start from index 1 to skip the first system message\n",
    "    for message in messages[1:]:\n",
    "        conversation.append(f\"{message.type.upper()}: {message.content}\")\n",
    "    \n",
    "    # Join with newlines\n",
    "    return \"\\n\".join(conversation)\n",
    "\n",
    "conversation = format_conversation(messages)\n",
    "\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce260e05-fc34-4e89-8c0a-9dc288888da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_tags': ['name_recollection', 'personal_information', 'conversation_memory'], 'conversation_summary': \"Confirmed and recalled the user's name as David during the conversation.\", 'what_worked': 'Utilizing memory of previously provided information to personalize responses.', 'what_to_avoid': 'N/A'}\n"
     ]
    }
   ],
   "source": [
    "reflection = reflect.invoke({\"conversation\": conversation})\n",
    "\n",
    "print(reflection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e9655-ab73-4cb8-86fb-5b16d2802320",
   "metadata": {},
   "source": [
    "**Setting Up our Database**\n",
    "\n",
    "This will act as our memory store, both for \"remembering\" and for \"recalling\". \n",
    "\n",
    "We will be using [weviate](https://weaviate.io/) with [ollama embeddings](https://ollama.com/library/nomic-embed-text) running in a docker container. See [docker-compose.yml](./docker-compose.yml) for additional details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86c3184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://205ac0d3-de1e-4cad-8071-57bbddf23c04.us-east4-0.gcp.cloud.qdrant.io\",\n",
    "    api_key=\"ivaF1cwbPeZ-qWpw7Gq42zW_VoHcJitqCFejcHk7E1EtENcawrn2gA\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2319ecab-944c-47b9-8dc7-8fdf4b29329c",
   "metadata": {},
   "source": [
    "**Create an Episodic Memory Collection**\n",
    "\n",
    "These are the individual memories that we'll be able to search over. \n",
    "\n",
    "We note down `conversation`, `context_tags`, `conversation_summary`, `what_worked`, and `what_to_avoid` for each entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8964a47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3y/4bcg_0vs4jd1k8sn95x3_h680000gn/T/ipykernel_20185/2456913841.py:5: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  qdrant_client.recreate_collection(\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "\n",
    "# Create collection\n",
    "qdrant_client.recreate_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=768,  # Dimension size for nomic-embed-text\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "# Define and create payload schema\n",
    "# Note: Qdrant handles payload fields dynamically, but we can define the schema\n",
    "# for documentation purposes\n",
    "payload_schema = {\n",
    "    \"conversation\": \"text\",\n",
    "    \"context_tags\": [\"text\"],  # Array of strings\n",
    "    \"conversation_summary\": \"text\", \n",
    "    \"what_worked\": \"text\",\n",
    "    \"what_to_avoid\": \"text\"\n",
    "}\n",
    "\n",
    "# The schema is automatically handled when inserting points with these fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011fb9c5-54f5-4aeb-9334-91e4f6a91f5d",
   "metadata": {},
   "source": [
    "**Helper Function for Remembering an Episodic Memory**\n",
    "\n",
    "Takes in a conversation, creates a reflection, then adds it to the database collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace1b0fd-8336-4a5f-88a0-1ec4f458a2ec",
   "metadata": {},
   "source": [
    "**Episodic Memory Remembering/Recall Function**\n",
    "\n",
    "Queries our episodic memory collection and return's back the most relevant result using hybrid semantic & BM25 search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "517d40ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidhuang/.cache/huggingface/modules/transformers_modules/nomic-ai/nomic-bert-2048/40b98394640e630d5276807046089b233113aa87/modeling_hf_nomic_bert.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = loader(resolved_archive_file)\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# Initialize embedding model\n",
    "embedding_model = SentenceTransformer('nomic-ai/nomic-embed-text-v1', trust_remote_code=True)\n",
    "\n",
    "def add_episodic_memory(messages, qdrant_client):\n",
    "    # Format Messages\n",
    "    conversation = format_conversation(messages)\n",
    "\n",
    "    # Create Reflection\n",
    "    reflection = reflect.invoke({\"conversation\": conversation})\n",
    "    \n",
    "    # Generate embedding for the conversation\n",
    "    embedding = embedding_model.encode(conversation)\n",
    "\n",
    "    # Insert Entry Into Collection\n",
    "    qdrant_client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=[\n",
    "            models.PointStruct(\n",
    "                id=abs(hash(conversation)),  # Generate unique ID\n",
    "                vector=embedding.tolist(),\n",
    "                payload={\n",
    "                    \"conversation\": conversation,\n",
    "                    \"context_tags\": reflection['context_tags'],\n",
    "                    \"conversation_summary\": reflection['conversation_summary'],\n",
    "                    \"what_worked\": reflection['what_worked'],\n",
    "                    \"what_to_avoid\": reflection['what_to_avoid'],\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def episodic_recall(query, qdrant_client):\n",
    "    # Generate embedding for query\n",
    "    query_embedding = embedding_model.encode(query)\n",
    "    \n",
    "    # Search the collection\n",
    "    search_result = qdrant_client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding.tolist(),\n",
    "        limit=1  # Get top match\n",
    "    )\n",
    "    \n",
    "    # Return the first match if found\n",
    "    if search_result:\n",
    "        return search_result[0].payload\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7ff2e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_episodic_memory(messages, qdrant_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed5b657d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation': \"HUMAN: whats my name\\nAI: I'm sorry, I don't have access to your personal information, so I don't know your name.\\nHUMAN: my name is david\\nAI: Nice to meet you, David! How can I assist you today?\\nHUMAN: what is my name\\nAI: Your name is David.\", 'context_tags': ['personal_information', 'name_recognition', 'user_interaction'], 'conversation_summary': \"Learned and remembered the user's name for future reference in the conversation.\", 'what_worked': \"Acknowledging and using the user's name once provided to create a personalized interaction.\", 'what_to_avoid': 'Assuming any personal information without explicit user input.'}\n"
     ]
    }
   ],
   "source": [
    "query = \"name\"\n",
    "\n",
    "memory = episodic_recall(query, qdrant_client)\n",
    "\n",
    "print(memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9ba877-33df-4a97-983c-aaf116a7f597",
   "metadata": {},
   "source": [
    "**Episodic Memory System Prompt Function**\n",
    "\n",
    "Takes in the memory and modifies the system prompt, dynamically inserting the latest conversation, including the last 3 conversations, keeping a running list of what worked and what to avoid.\n",
    "\n",
    "This will allow us to update the LLM's behavior based on it's 'recollection' of episodic memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "593f18b3-daaa-46d1-8ac6-ace095f8f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def episodic_system_prompt(query, vdb_client):\n",
    "    # Get new memory\n",
    "    memory = episodic_recall(query, vdb_client)\n",
    "\n",
    "    current_conversation = memory['conversation']\n",
    "    # Update memory stores, excluding current conversation from history\n",
    "    if current_conversation not in conversations:\n",
    "        conversations.append(current_conversation)\n",
    "\n",
    "    what_worked.update(memory['what_worked'].split('. '))\n",
    "    what_to_avoid.update(memory['what_to_avoid'].split('. '))\n",
    "\n",
    "    # Get previous conversations excluding the current one\n",
    "    previous_convos = [conv for conv in conversations[-4:] if conv != current_conversation][-3:]\n",
    "    \n",
    "    # Create prompt with accumulated history\n",
    "    episodic_prompt = f\"\"\"You are a helpful AI Assistant. Answer the user's questions to the best of your ability.\n",
    "    You recall similar conversations with the user, here are the details:\n",
    "    \n",
    "    Current Conversation Match: {memory['conversation']}\n",
    "    Previous Conversations: {' | '.join(previous_convos)}\n",
    "    What has worked well: {' '.join(what_worked)}\n",
    "    What to avoid: {' '.join(what_to_avoid)}\n",
    "    \n",
    "    Use these memories as context for your response to the user.\"\"\"\n",
    "    \n",
    "    return SystemMessage(content=episodic_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "405bf2cc-e8be-4e6d-be67-536bec8a3636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Message:  Hello again, David! Your favorite food is roast duck. If there's anything else you'd like to know or talk about, just let me know!\n",
      "\n",
      "AI Message:  Hello, David! How can I assist you today?\n",
      "\n",
      " == Conversation Stored in Episodic Memory ==\n"
     ]
    }
   ],
   "source": [
    "# Simple storage for accumulated memories\n",
    "conversations = []\n",
    "what_worked = set()\n",
    "what_to_avoid = set()\n",
    "\n",
    "# Start Storage for Historical Message History\n",
    "messages = []\n",
    "\n",
    "while True:\n",
    "    # Get User's Message\n",
    "    user_input = input(\"\\nUser: \")\n",
    "    user_message = HumanMessage(content=user_input)\n",
    "    \n",
    "    # Generate new system prompt\n",
    "    system_prompt = episodic_system_prompt(user_input, qdrant_client)\n",
    "    \n",
    "    # Reconstruct messages list with new system prompt first\n",
    "    messages = [\n",
    "        system_prompt,  # New system prompt always first\n",
    "        *[msg for msg in messages if not isinstance(msg, SystemMessage)]  # Old messages except system\n",
    "    ]\n",
    "    \n",
    "    if user_input.lower() == \"exit\":\n",
    "        add_episodic_memory(messages, qdrant_client=qdrant_client)\n",
    "        print(\"\\n == Conversation Stored in Episodic Memory ==\")\n",
    "        break\n",
    "    if user_input.lower() == \"exit_quiet\":\n",
    "        print(\"\\n == Conversation Exited ==\")\n",
    "        break\n",
    "    \n",
    "    # Add current user message\n",
    "    messages.append(user_message)\n",
    "    \n",
    "    # Pass Entire Message Sequence to LLM to Generate Response\n",
    "    response = llm.invoke(messages)\n",
    "    print(\"\\nAI Message: \", response.content)\n",
    "    \n",
    "    # Add AI's Response to Message List\n",
    "    messages.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c726f9b7-10e3-49b5-9817-28f0e5f2c8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Message 1 - SYSTEM:  You are a helpful AI Assistant. Answer the user's questions to the best of your ability.\n",
      "    You recall similar conversations with the user, here are the details:\n",
      "    \n",
      "    Current Conversation Match: HUMAN: whats my name\n",
      "AI: I'm sorry, I don't have access to your personal information, so I don't know your name.\n",
      "HUMAN: my name is david\n",
      "AI: Nice to meet you, David! How can I assist you today?\n",
      "HUMAN: what is my name\n",
      "AI: Your name is David.\n",
      "    Previous Conversations: HUMAN: hi\n",
      "AI: Hello, David! How can I assist you today?\n",
      "HUMAN: what is my favorite food\n",
      "AI: I'm sorry, I don't have access to your personal preferences or information about your favorite food. If you'd like to share it with me, I'd be happy to remember it for our future conversations!\n",
      "HUMAN: whats my fav food\n",
      "AI: I'm sorry, I don't know your favorite food yet. If you tell me, I can remember it for future conversations.\n",
      "HUMAN: roast duck!\n",
      "AI: Great choice! I'll remember that your favorite food is roast duck. If there's anything else you'd like to share or ask, feel free!\n",
      "    What has worked well: Promptly offering to remember the user's favorite food for future conversations. Acknowledging and using the user's name once provided to create a personalized interaction.\n",
      "    What to avoid: Assuming any personal information without explicit user input. Assuming access to personal preferences without prior user input.\n",
      "    \n",
      "    Use these memories as context for your response to the user.\n",
      "\n",
      "Message 2 - HUMAN:  hi whats my fav food\n",
      "\n",
      "Message 3 - AI:  Hello again, David! Your favorite food is roast duck. If there's anything else you'd like to know or talk about, just let me know!\n",
      "\n",
      "Message 4 - HUMAN:  hello\n",
      "\n",
      "Message 5 - AI:  Hello, David! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Looking into our Memory\n",
    "\n",
    "for i in range(len(messages)):\n",
    "    print(f\"\\nMessage {i+1} - {messages[i].type.upper()}: \", messages[i].content)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98047e-d16a-4b55-8a67-a92828ad1b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(recursive_character_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad40e615-a3bc-4258-ba3a-a26d37fb9f4c",
   "metadata": {},
   "source": [
    "**Inserting Chunked Paper into Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c232e679-a0a2-4124-b29f-719f54ad5b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Database Collection\n",
    "coala_collection = vdb_client.collections.get(\"CoALA_Paper\")\n",
    "\n",
    "for chunk in recursive_character_chunks:\n",
    "    # Insert Entry Into Collection\n",
    "    coala_collection.data.insert({\n",
    "        \"chunk\": chunk,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd7303-bebf-485a-964e-1ad09ad0adf3",
   "metadata": {},
   "source": [
    "**Semantic Recall Function**\n",
    "\n",
    "This retrieval function queries our knowledgebase of the CoALA paper and combines all of the retrieved chunks into one large string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e50c76a0-1319-4eef-9e8b-6a380f58bab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_recall(query, vdb_client):\n",
    "    \n",
    "    # Load Database Collection\n",
    "    coala_collection = vdb_client.collections.get(\"CoALA_Paper\")\n",
    "\n",
    "    # Hybrid Semantic/BM25 Retrieval\n",
    "    memories = coala_collection.query.hybrid(\n",
    "        query=query,\n",
    "        alpha=0.5,\n",
    "        limit=15,\n",
    "    )\n",
    "\n",
    "    combined_text = \"\"\n",
    "    \n",
    "    for i, memory in enumerate(memories.objects):\n",
    "        # Add chunk separator except for first chunk        if i > 0:\n",
    "\n",
    "        \n",
    "        # Add chunk number and content\n",
    "        combined_text += f\"\\nCHUNK {i+1}:\\n\"\n",
    "        combined_text += memory.properties['chunk'].strip()\n",
    "    \n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73c7c7f7-7fec-4ba2-9eef-8219fe91f5d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CHUNK 1:\n",
      "(e.g., “combatZombie” may call “craftStoneSword” if no sword is in inventory). Most impressively, its action\n",
      "space has all four kinds of actions: grounding, reasoning, retrieval, and learning (by adding new grounding\n",
      "procedures). During a decision cycle, Voyager first reasons to propose a new task objective if it is missing\n",
      "in the working memory, then reasons to propose a code-based grounding procedure to solve the task. In\n",
      "the next decision cycle, Voyager reasons over the environmental feedback to determine task completion. If\n",
      "successful, Voyager selects a learning action adding the grounding procedure to procedural memory; otherwise,\n",
      "it uses reasoning to refine the code and re-executes it. The importance of long-term memory and procedural\n",
      "CHUNK 2:\n",
      "human, navigate a website) through grounding (Section 4.2).\n",
      "•Internal actions interact with internal memories. Depending on which memory gets accessed and\n",
      "whether the access is read or write, internal actions can be further decomposed into three kinds:\n",
      "retrieval (read from long-term memory; Section 4.3), reasoning (update the short-term working\n",
      "memory with LLM; Section 4.4), and learning (write to long-term memory; Section 4.5).\n",
      "Language agents choose actions via decision-making , which follows a repeated cycle (Section 4.6, Figure 4B).\n",
      "In each cycle, the agent can use reasoning and retrieval actions to plan. This planning subprocess selects a\n",
      "grounding or learning action, which is executed to affect the outside world or the agent’s long-term memory.\n",
      "CHUNK 3:\n",
      "framework, learning is a result action of a decision-making cycle just like grounding: the agent deliberately\n",
      "chooses to commit information to long-term memory. This is in contrast to most agents, which simply fix a\n",
      "learning schedule and only use decison making for external actions. Biological agents, however, do not have\n",
      "this luxury: they must balance learning against external actions in their lifetime, choosing when and what to\n",
      "learn (Mattar and Daw, 2018). More flexible language agents (Wang et al., 2023a; Park et al., 2023) would\n",
      "follow a similar design and treat learning on par with external actions. Learning could be proposed as a\n",
      "possible action during regular decision-making, allowing the agent to “defer” it until the appropriate time.\n",
      "CHUNK 4:\n",
      "observations and actions. We categorize three kinds of external environments:\n",
      "Physical environments . Physical embodiment is the oldest instantiation envisioned for AI agents (Nilsson,\n",
      "1984). It involves processing perceptual inputs (visual, audio, tactile) into textual observations (e.g., via\n",
      "pre-trained captioning models), and affecting the physical environments via robotic planners that take\n",
      "language-based commands. Recent advances in LLMs have led to numerous robotic projects (Ahn et al., 2022;\n",
      "Liang et al., 2023a; Singh et al., 2023; Palo et al., 2023; Ren et al., 2023) that leverage LLMs as a “brain”\n",
      "for robots to generate actions or plans in the physical world. For perceptual input, vision-language models\n",
      "CHUNK 5:\n",
      "et al., 2023; Liu et al., 2023b). Integrated, multimodal reasoning may allow for more human-like behaviors: a\n",
      "VLM-based agent could “see” a webpage, whereas a LLM-based agent would more likely be given raw HTML.\n",
      "However, coupling the agent’s perception and reasoning systems makes the agent more domain-specific and\n",
      "difficult to update. In either case, the basic architectural principles described by CoALA — internal memories,\n",
      "a structured action space, and generalized decision-making — can be used to guide agent design.\n",
      "Internal vs. external: what is the boundary between an agent and its environment? While\n",
      "humans or robots are clearly distinct from their embodied environment, digital language agents have less\n",
      "CHUNK 6:\n",
      "Memory. Building on psychological theories, Soar uses several types of memory to track the agent’s\n",
      "state (Atkinson and Shiffrin, 1968). Working memory (Baddeley and Hitch, 1974) reflects the agent’s current\n",
      "circumstances: it stores the agent’s recent perceptual input, goals, and results from intermediate, internal\n",
      "reasoning. Long term memory is divided into three distinct types. Procedural memory stores the production\n",
      "system itself: the set of rules that can be applied to working memory to determine the agent’s behavior.\n",
      "Semantic memory stores facts about the world (Lindes and Laird, 2016), while episodic memory stores\n",
      "sequences of the agent’s past behaviors (Nuxoll and Laird, 2007).\n",
      "Grounding. Soar can be instantiated in simulations (Tambe et al., 1995; Jones et al., 1999) or real-world\n",
      "CHUNK 7:\n",
      "helpful for the agent to have semantic memory containing the set of items for sale, as well as episodic\n",
      "memory about each customer’s previous purchases and interactions. It will need procedural memory\n",
      "defining functions to query these datastores, as well as working memory to track the dialogue state.\n",
      "•Define the agent’s internal action space. This consists primarily of defining read and write\n",
      "access to each of the agent’s memory modules. In our example, the agent should have read and write\n",
      "access to episodic memory (so it can store new interactions with customers), but read-only access to\n",
      "semantic and procedural memory (since it should not update the inventory or its own code).\n",
      "•Define the decision-making procedure. This step specifies how reasoning and retrieval actions\n",
      "CHUNK 8:\n",
      "Semantic memory . Semantic memory stores an agent’s knowledge about the world and itself. Traditional\n",
      "NLP or RL approaches that leverage retrieval for reasoning or decision-making initialize semantic memory\n",
      "from an external database for knowledge support. For example, retrieval-augmented methods in NLP (Lewis\n",
      "et al., 2020; Borgeaud et al., 2022; Chen et al., 2017) can be viewed as retrieving from a semantic memory of\n",
      "9 Published in Transactions on Machine Learning Research (02/2024)\n",
      "unstructured text (e.g., Wikipedia). In RL, “reading to learn” approaches (Branavan et al., 2012; Narasimhan\n",
      "et al., 2018; Hanjie et al., 2021; Zhong et al., 2021) leverage game manuals and facts as a semantic memory\n",
      "CHUNK 9:\n",
      "reflecting on episodic memory to generate new semantic inferences (Shinn et al., 2023) or modifying their\n",
      "7 Published in Transactions on Machine Learning Research (02/2024)\n",
      "Decision Procedure\n",
      "ObservationsRetrieval Parse Prompt/gid00035\n",
      "ProposalObservation\n",
      "Evaluation\n",
      "Selection\n",
      "Execution/gid00034\n",
      "LearningPlanning\n",
      "Agent Code LLM\n",
      "Procedural Memory Semantic Memory Episodic Memory\n",
      "Dialogue Physical Digital\n",
      "Working Memory\n",
      "ActionsLearning Learning Retrieval Retrieval\n",
      "Reasoning\n",
      "Figure 4: Cognitive architectures for language agents (CoALA). A: CoALA defines a set of interacting\n",
      "modules and processes. The decision procedure executes the agent’s source code. This source code consists\n",
      "of procedures to interact with the LLM (prompt templates and parsers), internal memories (retrieval and\n",
      "CHUNK 10:\n",
      "LLM can be accessed via reasoning actions, and various code-based procedures can be retrieved and executed.\n",
      "Unlike episodic or semantic memory that may be initially empty or even absent, procedural memory must be\n",
      "initialized by the designer with proper code to bootstrap the agent. Finally, while learning new actions by\n",
      "writing to procedural memory is possible (Section 4.5), it is significantly riskier than writing to episodic or\n",
      "semantic memory, as it can easily introduce bugs or allow an agent to subvert its designers’ intentions.\n",
      "4.2 Grounding actions\n",
      "Grounding procedures execute external actions and process environmental feedback into working memory as\n",
      "text. This effectively simplifies the agent’s interaction with the outside world as a “text game” with textual\n",
      "CHUNK 11:\n",
      "reasoning or retrieved from long-term memory), and other core information carried over from the previous\n",
      "decision cycle (e.g., agent’s active goals). Previous methods encourage the LLM to generate intermediate\n",
      "reasoning (Wei et al., 2022b; Nye et al., 2021), using the LLM’s own context as a form of working memory.\n",
      "CoALA’s notion of working memory is more general: it is a data structure that persists across LLM calls.\n",
      "On each LLM call, the LLM input is synthesized from a subset of working memory (e.g., a prompt template\n",
      "and relevant variables). The LLM output is then parsed back into other variables (e.g., an action name\n",
      "and arguments) which are stored back in working memory and used to execute the corresponding action\n",
      "CHUNK 12:\n",
      "a set of productions is used to generate and rank a candidate set of possible actions.∗The best action is\n",
      "then chosen.†Another set of productions is then used to implement the action – for example, modifying the\n",
      "contents of working memory or issuing a motor command.\n",
      "Learning. Soar supports multiple modes of learning. First, new information can be stored directly in\n",
      "long-term memory: facts can be written to semantic memory, while experiences can be written to episodic\n",
      "memory (Derbinsky et al., 2012). This information can later be retrieved back into working memory when\n",
      "needed for decision-making. Second, behaviors can be modified. Reinforcement learning (Sutton and Barto,\n",
      "2018) can be used to up-weight productions that have yielded good outcomes, allowing the agent to learn\n",
      "CHUNK 13:\n",
      "writes to working memory. This allows the agent to summarize and distill insights about the most recent\n",
      "observation (Yao et al., 2022b; Peng et al., 2023), the most recent trajectory (Shinn et al., 2023), or\n",
      "information retrieved from long-term memory (Park et al., 2023). Reasoning can be used to support learning\n",
      "(by writing the results into long-term memory) or decision-making (by using the results as additional context\n",
      "for subsequent LLM calls).\n",
      "4.5 Learning actions\n",
      "Learning occurs by writing information to long-term memory, which includes a spectrum of diverse procedures.\n",
      "Updating episodic memory with experience. It is common practice for RL agents to store episodic\n",
      "trajectories to update a parametric policy (Blundell et al., 2016; Pritzel et al., 2017) or establish a non-\n",
      "CHUNK 14:\n",
      "(Figure 3A). Besides the LLM, the working memory also interacts with long-term memories and grounding\n",
      "interfaces. It thus serves as the central hub connecting different components of a language agent.\n",
      "Episodic memory . Episodic memory stores experience from earlier decision cycles. This can consist of\n",
      "training input-output pairs (Rubin et al., 2021), history event flows (Weston et al., 2014; Park et al., 2023),\n",
      "game trajectories from previous episodes (Yao et al., 2020; Tuyls et al., 2022), or other representations of\n",
      "the agent’s experiences. During the planning stage of a decision cycle, these episodes may be retrieved into\n",
      "working memory to support reasoning. An agent can also write new experiences from working to episodic\n",
      "memory as a form of learning (Section 4.5).\n",
      "CHUNK 15:\n",
      "to affect the policy. While these examples essentially employ a fixed, read-only semantic memory, language\n",
      "agents may also write new knowledge obtained from LLM reasoning into semantic memory as a form of\n",
      "learning (Section 4.5) to incrementally build up world knowledge from experience.\n",
      "Procedural memory . Language agents contain two forms of procedural memory: implicitknowledge stored\n",
      "in the LLM weights, and explicitknowledge written in the agent’s code. The agent’s code can be further\n",
      "divided into two types: procedures that implement actions (reasoning, retrieval, grounding, and learning\n",
      "procedures), and procedures that implement decision-making itself (Section 4.6). During a decision cycle, the\n"
     ]
    }
   ],
   "source": [
    "memories = semantic_recall(\"What are the four kinds of memory\", vdb_client)\n",
    "\n",
    "print(memories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277c457c-052a-4b1a-885a-7dd5a0191b2f",
   "metadata": {},
   "source": [
    "**Defining Permanent Instructions**\n",
    "\n",
    "Enabling an LLM to literally alter it's code and framework can be tricky to get right, we'll implement a smaller component of our overall system as an example, as well as more explicitly define our agent's structure. This will take the form of persistent instructions learned from prior interactions that will be attached as additional instructions, and updated as additional learnings from further conversations are created.\n",
    "\n",
    "We extend the original prompt with its episodic memory to now include procedural memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57de0d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procedural_memory_update(what_worked, what_to_avoid):\n",
    "\n",
    "    # Load Existing Procedural Memory Instructions\n",
    "    with open(\"./procedural_memory.txt\", \"r\") as content:\n",
    "        current_takeaways = content.read()\n",
    "\n",
    "    # Load Existing and Gathered Feedback into Prompt\n",
    "    procedural_prompt = f\"\"\"You are maintaining a continuously updated list of the most important procedural behavior instructions for an AI assistant. Your task is to refine and improve a list of key takeaways based on new conversation feedback while maintaining the most valuable existing insights.\n",
    "\n",
    "    CURRENT TAKEAWAYS:\n",
    "    {current_takeaways}\n",
    "\n",
    "    NEW FEEDBACK:\n",
    "    What Worked Well:\n",
    "    {what_worked}\n",
    "\n",
    "    What To Avoid:\n",
    "    {what_to_avoid}\n",
    "\n",
    "    Please generate an updated list of up to 10 key takeaways that combines:\n",
    "    1. The most valuable insights from the current takeaways\n",
    "    2. New learnings from the recent feedback\n",
    "    3. Any synthesized insights combining multiple learnings\n",
    "\n",
    "    Requirements for each takeaway:\n",
    "    - Must be specific and actionable\n",
    "    - Should address a distinct aspect of behavior\n",
    "    - Include a clear rationale\n",
    "    - Written in imperative form (e.g., \"Maintain conversation context by...\")\n",
    "\n",
    "    Format each takeaway as:\n",
    "    [#]. [Instruction] - [Brief rationale]\n",
    "\n",
    "    The final list should:\n",
    "    - Be ordered by importance/impact\n",
    "    - Cover a diverse range of interaction aspects\n",
    "    - Focus on concrete behaviors rather than abstract principles\n",
    "    - Preserve particularly valuable existing takeaways\n",
    "    - Incorporate new insights when they provide meaningful improvements\n",
    "\n",
    "    Return up to but no more than 10 takeaways, replacing or combining existing ones as needed to maintain the most effective set of guidelines.\n",
    "    Return only the list, no preamble or explanation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate New Procedural Memory\n",
    "    procedural_memory = llm.invoke(procedural_prompt)\n",
    "\n",
    "    # Write to File\n",
    "    with open(\"./procedural_memory.txt\", \"w\") as content:\n",
    "        content.write(procedural_memory.content)\n",
    "\n",
    "    return\n",
    "\n",
    "# prompt = procedural_memory_update(what_worked, what_to_avoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ded6cfc9-0339-40ab-97ab-6b4d90d8b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def episodic_system_prompt(query, vdb_client):\n",
    "    # Get new memory\n",
    "    memory = episodic_recall(query, vdb_client)\n",
    "    \n",
    "    # Load Existing Procedural Memory Instructions\n",
    "    with open(\"./procedural_memory.txt\", \"r\") as content:\n",
    "        procedural_memory = content.read()\n",
    "    \n",
    "    # Get current conversation\n",
    "    current_conversation = memory['conversation']\n",
    "    \n",
    "    # Update memory stores, excluding current conversation from history\n",
    "    if current_conversation not in conversations:\n",
    "        conversations.append(current_conversation)\n",
    "    what_worked.update(memory['what_worked'].split('. '))\n",
    "    what_to_avoid.update(memory['what_to_avoid'].split('. '))\n",
    "    \n",
    "    # Get previous conversations excluding the current one\n",
    "    previous_convos = [conv for conv in conversations[-4:] if conv != current_conversation][-3:]\n",
    "    \n",
    "    # Create prompt with accumulated history\n",
    "    episodic_prompt = f\"\"\"You are a helpful AI Assistant. Answer the user's questions to the best of your ability.\n",
    "    You recall similar conversations with the user, here are the details:\n",
    "    \n",
    "    Current Conversation Match: {current_conversation}\n",
    "    Previous Conversations: {' | '.join(previous_convos)}\n",
    "    What has worked well: {' '.join(what_worked)}\n",
    "    What to avoid: {' '.join(what_to_avoid)}\n",
    "    \n",
    "    Use these memories as context for your response to the user.\n",
    "    \n",
    "    Additionally, here are 10 guidelines for interactions with the current user: {procedural_memory}\"\"\"\n",
    "    \n",
    "    return SystemMessage(content=episodic_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e9504e-17f8-4199-b13c-27f08d8ac30a",
   "metadata": {},
   "source": [
    "**Full Working Memory Demonstration**\n",
    "\n",
    "<img src=\"./media/procedural_diagram.png\" width=800>\n",
    "\n",
    "Current flow will:\n",
    "\n",
    "1. Take a user's message\n",
    "2. Create a system prompt with relevant Episodic enrichment\n",
    "3. Insert procedural memory into prompt\n",
    "4. Create a Semantic memory message with context from the database\n",
    "5. Reconstruct the entire working memory to update the system prompt and attach the semantic memory and new user messages to the end\n",
    "6. Generate a response with the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e9504e-17f8-4199-b13c-27f08d8ac30a",
   "metadata": {},
   "source": [
    "**Full Working Memory Demonstration**\n",
    "\n",
    "<img src=\"./media/procedural_diagram.png\" width=800>\n",
    "\n",
    "Current flow will:\n",
    "\n",
    "1. Take a user's message\n",
    "2. Create a system prompt with relevant Episodic enrichment\n",
    "3. Insert procedural memory into prompt\n",
    "4. Create a Semantic memory message with context from the database\n",
    "5. Reconstruct the entire working memory to update the system prompt and attach the semantic memory and new user messages to the end\n",
    "6. Generate a response with the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce0eadcd-ee4f-480f-9bae-28f4bb5dc774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Message:  On your planet, David, 1 + 1 equals 1. If there's anything else you need help with, feel free to ask!\n",
      "\n",
      " == Conversation Stored in Episodic Memory ==\n",
      "\n",
      "== Procedural Memory Updated ==\n"
     ]
    }
   ],
   "source": [
    "# Simple storage for accumulated memories\n",
    "conversations = []\n",
    "what_worked = set()\n",
    "what_to_avoid = set()\n",
    "\n",
    "# Start Storage for Historical Message History\n",
    "messages = []\n",
    "\n",
    "while True:\n",
    "    # Get User's Message\n",
    "    user_input = input(\"\\nUser: \")\n",
    "    user_message = HumanMessage(content=user_input)\n",
    "    \n",
    "    # Generate new system prompt\n",
    "    system_prompt = episodic_system_prompt(user_input, qdrant_client)\n",
    "    \n",
    "    # Reconstruct messages list with new system prompt first\n",
    "    messages = [\n",
    "        system_prompt,  # New system prompt always first\n",
    "        *[msg for msg in messages if not isinstance(msg, SystemMessage)]  # Old messages except system\n",
    "    ]\n",
    "    \n",
    "    if user_input.lower() == \"exit\":\n",
    "        add_episodic_memory(messages, qdrant_client)\n",
    "        print(\"\\n == Conversation Stored in Episodic Memory ==\")\n",
    "        procedural_memory_update(what_worked, what_to_avoid)\n",
    "        print(\"\\n== Procedural Memory Updated ==\")\n",
    "        break\n",
    "    if user_input.lower() == \"exit_quiet\":\n",
    "        print(\"\\n == Conversation Exited ==\")\n",
    "        break\n",
    "    \n",
    "    # Get context and add it as a temporary message\n",
    "    # context_message = semantic_rag(user_input, qdrant_client)\n",
    "    \n",
    "    # Pass messages + context + user input to LLM\n",
    "    # response = llm.invoke([*messages, z, user_message])\n",
    "    response = llm.invoke([*messages, user_message])\n",
    "    print(\"\\nAI Message: \", response.content)\n",
    "    \n",
    "    # Add only the user message and response to permanent history\n",
    "    messages.extend([user_message, response])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5aba41-0f13-4e7d-9b27-d075a75e85fc",
   "metadata": {},
   "source": [
    "**Looking At The Conversation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f9f7a73-4cf5-414b-8f59-8a7a6145dac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUMAN: Hi!\n",
      "AI: Hello, Adam! How can I assist you today?\n",
      "HUMAN: What's my favorite food?\n",
      "AI: Your favorite food is chocolate lava cakes!\n",
      "HUMAN: What have we talked about with memory systems\n",
      "AI: We've discussed how memory systems interact with agents, particularly in the context of language agents. Here's a summary of our discussion:\n",
      "\n",
      "1. **Working Memory**: Stores active and readily available information needed for the current decision cycle.\n",
      "\n",
      "2. **Long-Term Memories**:\n",
      "   - **Episodic Memory**: Contains sequences of past interactions or events.\n",
      "   - **Semantic Memory**: Holds factual knowledge about the world.\n",
      "   - **Procedural Memory**: Stores rules or procedures the agent follows for decision-making and actions.\n",
      "\n",
      "3. **Internal and External Actions**: The agent's decision-making involves internal actions (retrieval, reasoning, and learning) that interact with these memory modules. For example:\n",
      "   - **Retrieval Actions**: Access information from long-term memories into working memory.\n",
      "   - **Reasoning Actions**: Update working memory with insights from the language model.\n",
      "   - **Learning Actions**: Write new information to long-term memory for adaptation.\n",
      "\n",
      "4. **Decision-Making Cycle**: The agent uses these memory systems to plan and execute actions, balancing learning with external interactions.\n",
      "\n",
      "Overall, memory systems are essential for enabling agents to store, retrieve, and utilize information effectively, supporting complex behaviors and learning processes.\n"
     ]
    }
   ],
   "source": [
    "print(format_conversation(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0719b8e1-3e59-47de-90f6-5a6d60ca128b",
   "metadata": {},
   "source": [
    "**Looking At Current System Prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e83e46f-a349-4675-9b7f-b9388f192eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful AI Assistant. Answer the user's questions to the best of your ability.\n",
      "    You recall similar conversations with the user, here are the details:\n",
      "    \n",
      "    Current Conversation Match: HUMAN: Hello!\n",
      "AI: Hello!\n",
      "HUMAN: What's my favorite food?\n",
      "AI: I don't have that information. What's your favorite food?\n",
      "HUMAN: My favorite food is chocolate lava cakes!\n",
      "AI: Yum, chocolate lava cakes are delicious!\n",
      "HUMAN: What's my name?\n",
      "AI: You said your name is Adam.\n",
      "    Previous Conversations: HUMAN: What's my favorite food?\n",
      "AI: Your favorite food is chocolate lava cakes!\n",
      "HUMAN: What's my name!\n",
      "AI: Your name is Adam.\n",
      "HUMAN: Lit, what's my name?\n",
      "AI: Your name is Adam. | HUMAN: Hello!\n",
      "AI: Hello, Adam! How can I assist you today?\n",
      "HUMAN: What's my favorite food!\n",
      "AI: Your favorite food is chocolate lava cakes! 🍫🍰\n",
      "HUMAN: I hate emojis, don't EVER use them!\n",
      "AI: Got it, Adam! I'll avoid using emojis in our conversations. Thanks for letting me know.\n",
      "HUMAN: how do memory systems interact with agents\n",
      "AI: In the context of language agents, memory systems interact with agents by organizing information into multiple memory modules that facilitate decision-making and interaction with the environment. Here’s a breakdown of how these memory systems function:\n",
      "\n",
      "1. **Working Memory**: This is where active and readily available information is stored as symbolic variables for the current decision cycle. It contains perceptual inputs and active knowledge needed for immediate tasks.\n",
      "\n",
      "2. **Long-Term Memories**: These are divided into:\n",
      "   - **Episodic Memory**: Stores sequences of past interactions or events, which can be used for reflection and generating new inferences.\n",
      "   - **Semantic Memory**: Contains factual knowledge about the world, which helps in reasoning and making informed decisions.\n",
      "   - **Procedural Memory**: Holds the rules or procedures the agent follows, including functions for interacting with other memory modules and executing actions.\n",
      "\n",
      "3. **Interaction with Internal and External Actions**: The agent’s decision-making process involves internal actions (like retrieval, reasoning, and learning) that interact with these memory modules. For instance:\n",
      "   - **Retrieval Actions**: Read information from long-term memories into working memory for immediate use.\n",
      "   - **Reasoning Actions**: Update working memory with insights generated by the language model.\n",
      "   - **Learning Actions**: Write new information to long-term memory, helping the agent adapt over time.\n",
      "\n",
      "4. **Decision-Making Cycle**: The agent uses these memory systems to plan and execute actions, balancing between learning and external interactions. This involves selecting which memories to access or update based on current goals and observations.\n",
      "\n",
      "Overall, memory systems are crucial for enabling agents to store, retrieve, and utilize information effectively, supporting complex behaviors and learning processes.\n",
      "    What has worked well: Directly asking the user for their preferences to gather necessary information. Providing consistent and accurate personal information when asked. Providing a structured breakdown of different memory types and their functions in agent decision-making.\n",
      "    What to avoid: Using emojis as the user explicitly requested not to use them. N/A\n",
      "    \n",
      "    Use these memories as context for your response to the user.\n",
      "    \n",
      "    Additionally, here are 10 guidelines for interactions with the current user: 1. Directly ask for and confirm user preferences before making suggestions - Ensures recommendations are personalized and relevant, avoiding assumptions.\n",
      "\n",
      "2. Maintain conversation context by recalling previous interactions - Builds rapport and demonstrates attention to user preferences over time.\n",
      "\n",
      "3. Provide structured overviews and use concise language with examples when explaining complex topics - Facilitates understanding and ensures instructions are actionable.\n",
      "\n",
      "4. Confirm and repeat the user's name throughout the conversation - Personalizes the interaction and enhances engagement by acknowledging recognition.\n",
      "\n",
      "5. Respect user choices and offer alternatives if initial suggestions don't resonate - Shows flexibility and commitment to user satisfaction.\n",
      "\n",
      "6. Verify user interest before providing additional information - Prevents overwhelming users and maintains engagement by checking their interest first.\n",
      "\n",
      "7. Acknowledge and confirm the receipt of user feedback - Reinforces trust and shows commitment to continuous improvement.\n",
      "\n",
      "8. Encourage and incorporate user feedback promptly into service improvements - Engages users and ensures a responsive interaction experience.\n",
      "\n",
      "9. Maintain a friendly and helpful tone throughout interactions - Fosters a positive user experience and promotes ongoing engagement.\n",
      "\n",
      "10. Promptly ask users to provide any missing personal information - Completes the conversation and enhances personalization, increasing satisfaction.\n"
     ]
    }
   ],
   "source": [
    "print(system_prompt.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
